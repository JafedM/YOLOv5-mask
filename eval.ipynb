{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda: True\n",
      "available GPU(s): 1\n",
      "0: {'name': 'NVIDIA GeForce RTX 3060 Ti', 'capability': [8, 6], 'total_momory': 8.0, 'sm_count': 38}\n",
      "\n",
      "device: cuda\n",
      "Automatic mixed precision (AMP) is enabled!\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pycocotools._mask'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 89\u001b[0m\n\u001b[0;32m     86\u001b[0m args\u001b[39m.\u001b[39mevaluation \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m     87\u001b[0m args\u001b[39m.\u001b[39meval_with_loss \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m---> 89\u001b[0m main(args)\n",
      "Cell \u001b[1;32mIn[1], line 30\u001b[0m, in \u001b[0;36mmain\u001b[1;34m(args)\u001b[0m\n\u001b[0;32m     27\u001b[0m     d_test \u001b[39m=\u001b[39m yolo\u001b[39m.\u001b[39mDALICOCODataLoader(\n\u001b[0;32m     28\u001b[0m         args\u001b[39m.\u001b[39mfile_root, args\u001b[39m.\u001b[39mann_file, args\u001b[39m.\u001b[39mbatch_size, collate_fn\u001b[39m=\u001b[39myolo\u001b[39m.\u001b[39mcollate_wrapper)\n\u001b[0;32m     29\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m---> 30\u001b[0m     dataset_test \u001b[39m=\u001b[39m yolo\u001b[39m.\u001b[39;49mdatasets(args\u001b[39m.\u001b[39;49mdataset, args\u001b[39m.\u001b[39;49mfile_root, args\u001b[39m.\u001b[39;49mann_file, train\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m) \u001b[39m# set train=True for eval\u001b[39;00m\n\u001b[0;32m     31\u001b[0m     sampler_test \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mutils\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mSequentialSampler(dataset_test)\n\u001b[0;32m     33\u001b[0m     batch_sampler_test \u001b[39m=\u001b[39m yolo\u001b[39m.\u001b[39mGroupedBatchSampler(\n\u001b[0;32m     34\u001b[0m         sampler_test, dataset_test\u001b[39m.\u001b[39maspect_ratios, args\u001b[39m.\u001b[39mbatch_size)\n",
      "File \u001b[1;32mc:\\Users\\jafse\\Documents\\Maestria cimat\\Proyecto tecnologico\\YOLOv5-PyTorch-master\\yolo\\datasets\\utils.py:18\u001b[0m, in \u001b[0;36mdatasets\u001b[1;34m(ds, *args, **kwargs)\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[39mreturn\u001b[39;00m VOCDataset(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     17\u001b[0m \u001b[39mif\u001b[39;00m ds \u001b[39m==\u001b[39m choice[\u001b[39m1\u001b[39m]:\n\u001b[1;32m---> 18\u001b[0m     \u001b[39mreturn\u001b[39;00m COCODataset(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     19\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     20\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39mds\u001b[39m\u001b[39m'\u001b[39m\u001b[39m must be in \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m, but got \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(choice, ds))\n",
      "File \u001b[1;32mc:\\Users\\jafse\\Documents\\Maestria cimat\\Proyecto tecnologico\\YOLOv5-PyTorch-master\\yolo\\datasets\\coco_dataset.py:11\u001b[0m, in \u001b[0;36mCOCODataset.__init__\u001b[1;34m(self, file_root, ann_file, train, transforms)\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, file_root, ann_file, train\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, transforms\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m     10\u001b[0m     \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m()\n\u001b[1;32m---> 11\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39mpycocotools\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcoco\u001b[39;00m \u001b[39mimport\u001b[39;00m COCO\n\u001b[0;32m     13\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfile_root \u001b[39m=\u001b[39m file_root\n\u001b[0;32m     14\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrain \u001b[39m=\u001b[39m train\n",
      "File \u001b[1;32mc:\\Users\\jafse\\Documents\\Maestria cimat\\Proyecto tecnologico\\YOLOv5-PyTorch-master\\pycocotools\\coco.py:55\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mcopy\u001b[39;00m\n\u001b[0;32m     54\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mitertools\u001b[39;00m\n\u001b[1;32m---> 55\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m mask \u001b[39mas\u001b[39;00m maskUtils\n\u001b[0;32m     56\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mos\u001b[39;00m\n\u001b[0;32m     57\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mcollections\u001b[39;00m \u001b[39mimport\u001b[39;00m defaultdict\n",
      "File \u001b[1;32mc:\\Users\\jafse\\Documents\\Maestria cimat\\Proyecto tecnologico\\YOLOv5-PyTorch-master\\pycocotools\\mask.py:3\u001b[0m\n\u001b[0;32m      1\u001b[0m __author__ \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mtsungyi\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m----> 3\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpycocotools\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_mask\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39m_mask\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[39m# Interface for manipulating masks stored in RLE format.\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[39m#\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[39m# RLE is a simple yet efficient format for storing binary masks. RLE\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     73\u001b[0m \u001b[39m# Code written by Piotr Dollar and Tsung-Yi Lin, 2015.\u001b[39;00m\n\u001b[0;32m     74\u001b[0m \u001b[39m# Licensed under the Simplified BSD License [see coco/license.txt]\u001b[39;00m\n\u001b[0;32m     76\u001b[0m iou         \u001b[39m=\u001b[39m _mask\u001b[39m.\u001b[39miou\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pycocotools._mask'"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import os\n",
    "import time\n",
    "import torch\n",
    "import yolo\n",
    "\n",
    "    \n",
    "def main(args):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() and args.use_cuda else \"cpu\")\n",
    "    cuda = device.type == \"cuda\"\n",
    "    if cuda: yolo.get_gpu_prop(show=True)\n",
    "    print(\"\\ndevice: {}\".format(device))\n",
    "    \n",
    "    args.amp = False\n",
    "    if cuda and torch.__version__ >= \"1.6.0\":\n",
    "        capability = torch.cuda.get_device_capability()[0]\n",
    "        if capability >= 7: # 7 refers to RTX series GPUs\n",
    "            args.amp = True\n",
    "            print(\"Automatic mixed precision (AMP) is enabled!\")\n",
    "            \n",
    "    # ---------------------- prepare data loader ------------------------------- #\n",
    "    \n",
    "    DALI = cuda & yolo.DALI & (args.dataset == \"coco\")\n",
    "    \n",
    "    if DALI:\n",
    "        print(\"Nvidia DALI is utilized!\")\n",
    "        d_test = yolo.DALICOCODataLoader(\n",
    "            args.file_root, args.ann_file, args.batch_size, collate_fn=yolo.collate_wrapper)\n",
    "    else:\n",
    "        dataset_test = yolo.datasets(args.dataset, args.file_root, args.ann_file, train=True) # set train=True for eval\n",
    "        sampler_test = torch.utils.data.SequentialSampler(dataset_test)\n",
    "\n",
    "        batch_sampler_test = yolo.GroupedBatchSampler(\n",
    "            sampler_test, dataset_test.aspect_ratios, args.batch_size)\n",
    "        \n",
    "        args.num_workers = min(os.cpu_count() // 2, 8, args.batch_size if args.batch_size > 1 else 0)\n",
    "        data_loader_test = torch.utils.data.DataLoader(\n",
    "            dataset_test, batch_sampler=batch_sampler_test, num_workers=args.num_workers,  \n",
    "            collate_fn=yolo.collate_wrapper, pin_memory=cuda)\n",
    "\n",
    "        d_test = yolo.DataPrefetcher(data_loader_test) if cuda else data_loader_test\n",
    "    \n",
    "    # -------------------------------------------------------------------------- #\n",
    "\n",
    "    yolo.setup_seed(3)\n",
    "    \n",
    "    model_sizes = {\"small\": (0.33, 0.5), \"medium\": (0.67, 0.75), \"large\": (1, 1), \"extreme\": (1.33, 1.25)}\n",
    "    num_classes = len(d_test.dataset.classes)\n",
    "    model = yolo.YOLOv5(num_classes, model_sizes[args.model_size], **args.kwargs).to(device)\n",
    "    model.head.eval_with_loss = args.eval_with_loss\n",
    "    \n",
    "    checkpoint = torch.load(args.ckpt_path, map_location=device)\n",
    "    if \"ema\" in checkpoint:\n",
    "        model.load_state_dict(checkpoint[\"ema\"][0])\n",
    "        print(checkpoint[\"eval_info\"])\n",
    "    else:\n",
    "        model.load_state_dict(checkpoint)\n",
    "\n",
    "    model.fuse()\n",
    "    print(\"evaluating...\")\n",
    "    B = time.time()\n",
    "    eval_output, iter_eval = yolo.evaluate(model, d_test, device, args, evaluation=args.evaluation)\n",
    "    B = time.time() - B\n",
    "    print(eval_output)\n",
    "    print(\"\\ntotal time of this evaluation: {:.2f} s, speed: {:.2f} FPS\".format(B, args.batch_size / iter_eval))\n",
    "    \n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser()\n",
    "    args = parser.parse_args([]) # [] is needed when using Jupyter Notebook.\n",
    "    \n",
    "    args.use_cuda = True\n",
    "    \n",
    "    args.dataset = \"coco\"\n",
    "    args.file_root = \"data/coco2017/val2017\"\n",
    "    args.ann_file = \"data/coco2017/annotations/instances_val2017.json\"\n",
    "    args.ckpt_path = \"yolov5s_official_2cf45318.pth\"\n",
    "    args.results = os.path.join(os.path.dirname(args.ckpt_path), \"results.json\")\n",
    "    \n",
    "    args.batch_size = 32\n",
    "    args.iters = -1\n",
    "    \n",
    "    args.model_size = \"small\"\n",
    "    args.kwargs = {\"img_sizes\": 640, \"score_thresh\": 0.1, \"detections\": 100} # mAP 34.6 FPS 451\n",
    "    #args.kwargs = {\"img_sizes\": 672, \"score_thresh\": 0.001, \"detections\": 300} # mAP 36.1. take more(2x-4x) time in total\n",
    "    args.evaluation = True\n",
    "    args.eval_with_loss = False\n",
    "    \n",
    "    main(args)\n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
