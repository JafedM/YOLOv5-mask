{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import time\n",
    "import torch\n",
    "import yolo\n",
    "\n",
    "    \n",
    "def main(args):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() and args.use_cuda else \"cpu\")\n",
    "    cuda = device.type == \"cuda\"\n",
    "    if cuda: yolo.get_gpu_prop(show=True)\n",
    "    print(\"\\ndevice: {}\".format(device))\n",
    "    \n",
    "    args.amp = False\n",
    "    if cuda and torch.__version__ >= \"1.6.0\":\n",
    "        capability = torch.cuda.get_device_capability()[0]\n",
    "        if capability >= 7: # 7 refers to RTX series GPUs\n",
    "            args.amp = True\n",
    "            print(\"Automatic mixed precision (AMP) is enabled!\")\n",
    "            \n",
    "    # ---------------------- prepare data loader ------------------------------- #\n",
    "    \n",
    "    DALI = cuda & yolo.DALI & (args.dataset == \"coco\")\n",
    "    \n",
    "    if DALI:\n",
    "        print(\"Nvidia DALI is utilized!\")\n",
    "        d_test = yolo.DALICOCODataLoader(\n",
    "            args.file_root, args.ann_file, args.batch_size, collate_fn=yolo.collate_wrapper)\n",
    "    else:\n",
    "        dataset_test = yolo.datasets(args.dataset, args.file_root, args.ann_file, train=True) # set train=True for eval\n",
    "        sampler_test = torch.utils.data.SequentialSampler(dataset_test)\n",
    "\n",
    "        batch_sampler_test = yolo.GroupedBatchSampler(\n",
    "            sampler_test, dataset_test.aspect_ratios, args.batch_size)\n",
    "        \n",
    "        args.num_workers = min(os.cpu_count() // 2, 8, args.batch_size if args.batch_size > 1 else 0)\n",
    "        data_loader_test = torch.utils.data.DataLoader(\n",
    "            dataset_test, batch_sampler=batch_sampler_test, num_workers=args.num_workers,  \n",
    "            collate_fn=yolo.collate_wrapper, pin_memory=cuda)\n",
    "\n",
    "        d_test = yolo.DataPrefetcher(data_loader_test) if cuda else data_loader_test\n",
    "    \n",
    "    # -------------------------------------------------------------------------- #\n",
    "\n",
    "    yolo.setup_seed(3)\n",
    "    \n",
    "    model_sizes = {\"small\": (0.33, 0.5), \"medium\": (0.67, 0.75), \"large\": (1, 1), \"extreme\": (1.33, 1.25)}\n",
    "    num_classes = len(d_test.dataset.classes)\n",
    "    model = yolo.YOLOv5(num_classes, model_sizes[args.model_size], **args.kwargs).to(device)\n",
    "    model.head.eval_with_loss = args.eval_with_loss\n",
    "    \n",
    "    checkpoint = torch.load(args.ckpt_path, map_location=device)\n",
    "    if \"ema\" in checkpoint:\n",
    "        model.load_state_dict(checkpoint[\"ema\"][0])\n",
    "        print(checkpoint[\"eval_info\"])\n",
    "    else:\n",
    "        model.load_state_dict(checkpoint)\n",
    "\n",
    "    model.fuse()\n",
    "    print(\"evaluating...\")\n",
    "    B = time.time()\n",
    "    eval_output, iter_eval = yolo.evaluate(model, d_test, device, args, evaluation=args.evaluation)\n",
    "    B = time.time() - B\n",
    "    print(eval_output)\n",
    "    print(\"\\ntotal time of this evaluation: {:.2f} s, speed: {:.2f} FPS\".format(B, args.batch_size / iter_eval))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resultados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo mask small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda: True\n",
      "available GPU(s): 1\n",
      "0: {'name': 'NVIDIA GeForce RTX 3060 Ti', 'capability': [8, 6], 'total_momory': 8.0, 'sm_count': 38}\n",
      "\n",
      "device: cuda\n",
      "Automatic mixed precision (AMP) is enabled!\n",
      "loading annotations into memory...\n",
      "Done (t=0.45s)\n",
      "creating index...\n",
      "index created!\n",
      "IoU metric: bbox\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.209\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.332\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.225\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.061\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.230\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.327\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.190\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.260\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.262\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.072\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.282\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.415\n",
      "\n",
      "evaluating...\n",
      "iter: 271.9, total: 142.8, model: 132.7\n",
      "all gather: 0.0s\n",
      "Loading and preparing results...\n",
      "DONE (t=0.20s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=9.99s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=1.50s).\n",
      "accumulate: 11.7s\n",
      "IoU metric: bbox\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.224\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.366\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.237\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.087\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.249\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.334\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.207\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.300\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.310\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.120\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.342\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.458\n",
      "\n",
      "\n",
      "total time of this evaluation: 56.13 s, speed: 241.10 FPS\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser()\n",
    "    args = parser.parse_args([]) # [] is needed when using Jupyter Notebook.\n",
    "    \n",
    "    args.use_cuda = True\n",
    "    \n",
    "    args.dataset = \"coco\"\n",
    "    args.file_root = \"data/coco2017/val2017\"\n",
    "    args.ann_file = \"data/coco2017/annotations/instances_val2017.json\"\n",
    "    args.ckpt_path = \"Varmedian/mask-s-200.pth\"\n",
    "    args.results = os.path.join(os.path.dirname(args.ckpt_path), \"results.json\")\n",
    "    \n",
    "    args.batch_size = 32\n",
    "    args.iters = -1\n",
    "    \n",
    "    args.model_size = \"small\"\n",
    "    args.kwargs = {\"img_sizes\": 420, \"score_thresh\": 0.1, \"detections\": 100} # mAP 34.6 FPS 451\n",
    "    #args.kwargs = {\"img_sizes\": 672, \"score_thresh\": 0.001, \"detections\": 300} # mAP 36.1. take more(2x-4x) time in total\n",
    "    args.evaluation = True\n",
    "    args.eval_with_loss = False\n",
    "    \n",
    "    main(args)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo mask medium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda: True\n",
      "available GPU(s): 1\n",
      "0: {'name': 'NVIDIA GeForce RTX 3060 Ti', 'capability': [8, 6], 'total_momory': 8.0, 'sm_count': 38}\n",
      "\n",
      "device: cuda\n",
      "Automatic mixed precision (AMP) is enabled!\n",
      "loading annotations into memory...\n",
      "Done (t=0.35s)\n",
      "creating index...\n",
      "index created!\n",
      "IoU metric: bbox\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.270\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.398\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.292\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.086\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.305\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.412\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.232\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.323\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.326\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.097\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.364\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.505\n",
      "\n",
      "evaluating...\n",
      "iter: 285.6, total: 159.7, model: 151.8\n",
      "all gather: 0.0s\n",
      "Loading and preparing results...\n",
      "DONE (t=0.04s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=10.03s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=1.60s).\n",
      "accumulate: 11.7s\n",
      "IoU metric: bbox\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.290\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.443\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.309\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.117\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.327\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.422\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.251\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.370\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.382\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.153\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.424\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.547\n",
      "\n",
      "\n",
      "total time of this evaluation: 58.44 s, speed: 210.78 FPS\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser()\n",
    "    args = parser.parse_args([]) # [] is needed when using Jupyter Notebook.\n",
    "    \n",
    "    args.use_cuda = True\n",
    "    \n",
    "    args.dataset = \"coco\"\n",
    "    args.file_root = \"data/coco2017/val2017\"\n",
    "    args.ann_file = \"data/coco2017/annotations/instances_val2017.json\"\n",
    "    args.ckpt_path = \"Varmedian/mask-m-200.pth\"\n",
    "    args.results = os.path.join(os.path.dirname(args.ckpt_path), \"results.json\")\n",
    "    \n",
    "    args.batch_size = 32\n",
    "    args.iters = -1\n",
    "    \n",
    "    args.model_size = \"medium\"\n",
    "    args.kwargs = {\"img_sizes\": 420, \"score_thresh\": 0.1, \"detections\": 100} # mAP 34.6 FPS 451\n",
    "    #args.kwargs = {\"img_sizes\": 672, \"score_thresh\": 0.001, \"detections\": 300} # mAP 36.1. take more(2x-4x) time in total\n",
    "    args.evaluation = True\n",
    "    args.eval_with_loss = False\n",
    "    \n",
    "    main(args)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VAR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo 10 fine small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda: True\n",
      "available GPU(s): 1\n",
      "0: {'name': 'NVIDIA GeForce RTX 3060 Ti', 'capability': [8, 6], 'total_momory': 8.0, 'sm_count': 38}\n",
      "\n",
      "device: cuda\n",
      "Automatic mixed precision (AMP) is enabled!\n",
      "loading annotations into memory...\n",
      "Done (t=0.37s)\n",
      "creating index...\n",
      "index created!\n",
      "IoU metric: bbox\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.196\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.314\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.211\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.051\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.218\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.316\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.181\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.244\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.246\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.056\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.267\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.401\n",
      "\n",
      "evaluating...\n",
      "iter: 211.7, total: 86.4, model: 78.5\n",
      "all gather: 0.0s\n",
      "Loading and preparing results...\n",
      "DONE (t=0.23s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=10.20s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=1.57s).\n",
      "accumulate: 12.0s\n",
      "IoU metric: bbox\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.213\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.350\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.223\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.075\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.239\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.325\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.199\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.286\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.296\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.102\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.328\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.444\n",
      "\n",
      "\n",
      "total time of this evaluation: 47.32 s, speed: 407.40 FPS\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser()\n",
    "    args = parser.parse_args([]) # [] is needed when using Jupyter Notebook.\n",
    "    \n",
    "    args.use_cuda = True\n",
    "    \n",
    "    args.dataset = \"coco\"\n",
    "    args.file_root = \"data/coco2017/val2017\"\n",
    "    args.ann_file = \"data/coco2017/annotations/instances_val2017.json\"\n",
    "    args.ckpt_path = \"Varmedian/var-s-210.pth\"\n",
    "    args.results = os.path.join(os.path.dirname(args.ckpt_path), \"results.json\")\n",
    "    \n",
    "    args.batch_size = 32\n",
    "    args.iters = -1\n",
    "    \n",
    "    args.model_size = \"small\"\n",
    "    args.kwargs = {\"img_sizes\": 420, \"score_thresh\": 0.1, \"detections\": 100} # mAP 34.6 FPS 451\n",
    "    #args.kwargs = {\"img_sizes\": 672, \"score_thresh\": 0.001, \"detections\": 300} # mAP 36.1. take more(2x-4x) time in total\n",
    "    args.evaluation = True\n",
    "    args.eval_with_loss = False\n",
    "    \n",
    "    main(args)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda: True\n",
      "available GPU(s): 1\n",
      "0: {'name': 'NVIDIA GeForce RTX 3060 Ti', 'capability': [8, 6], 'total_momory': 8.0, 'sm_count': 38}\n",
      "\n",
      "device: cuda\n",
      "Automatic mixed precision (AMP) is enabled!\n",
      "loading annotations into memory...\n",
      "Done (t=0.56s)\n",
      "creating index...\n",
      "index created!\n",
      "IoU metric: bbox\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.199\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.314\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.215\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.053\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.223\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.313\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.181\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.245\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.247\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.058\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.270\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.396\n",
      "\n",
      "evaluating...\n",
      "iter: 214.3, total: 89.8, model: 80.6\n",
      "all gather: 0.0s\n",
      "Loading and preparing results...\n",
      "DONE (t=0.04s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=9.90s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=1.51s).\n",
      "accumulate: 11.5s\n",
      "IoU metric: bbox\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.213\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.348\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.226\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.078\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.243\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.323\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.199\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.287\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.296\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.105\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.329\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.440\n",
      "\n",
      "\n",
      "total time of this evaluation: 47.18 s, speed: 396.91 FPS\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser()\n",
    "    args = parser.parse_args([]) # [] is needed when using Jupyter Notebook.\n",
    "    \n",
    "    args.use_cuda = True\n",
    "    \n",
    "    args.dataset = \"coco\"\n",
    "    args.file_root = \"data/coco2017/val2017\"\n",
    "    args.ann_file = \"data/coco2017/annotations/instances_val2017.json\"\n",
    "    args.ckpt_path = \"Varmedian/varmod-s-210.pth\"\n",
    "    args.results = os.path.join(os.path.dirname(args.ckpt_path), \"results.json\")\n",
    "    \n",
    "    args.batch_size = 32\n",
    "    args.iters = -1\n",
    "    \n",
    "    args.model_size = \"small\"\n",
    "    args.kwargs = {\"img_sizes\": 420, \"score_thresh\": 0.1, \"detections\": 100} # mAP 34.6 FPS 451\n",
    "    #args.kwargs = {\"img_sizes\": 672, \"score_thresh\": 0.001, \"detections\": 300} # mAP 36.1. take more(2x-4x) time in total\n",
    "    args.evaluation = True\n",
    "    args.eval_with_loss = False\n",
    "    \n",
    "    main(args)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo 10 fine medium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda: True\n",
      "available GPU(s): 1\n",
      "0: {'name': 'NVIDIA GeForce RTX 3060 Ti', 'capability': [8, 6], 'total_momory': 8.0, 'sm_count': 38}\n",
      "\n",
      "device: cuda\n",
      "Automatic mixed precision (AMP) is enabled!\n",
      "loading annotations into memory...\n",
      "Done (t=0.36s)\n",
      "creating index...\n",
      "index created!\n",
      "IoU metric: bbox\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.240\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.359\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.261\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.068\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.269\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.378\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.208\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.282\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.285\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.073\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.317\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.457\n",
      "\n",
      "evaluating...\n",
      "iter: 242.9, total: 115.5, model: 108.2\n",
      "all gather: 0.0s\n",
      "Loading and preparing results...\n",
      "DONE (t=0.04s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=10.19s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=1.47s).\n",
      "accumulate: 11.7s\n",
      "IoU metric: bbox\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.262\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.409\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.276\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.098\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.300\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.383\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.232\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.335\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.346\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.130\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.387\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.496\n",
      "\n",
      "\n",
      "total time of this evaluation: 51.90 s, speed: 295.64 FPS\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser()\n",
    "    args = parser.parse_args([]) # [] is needed when using Jupyter Notebook.\n",
    "    \n",
    "    args.use_cuda = True\n",
    "    \n",
    "    args.dataset = \"coco\"\n",
    "    args.file_root = \"data/coco2017/val2017\"\n",
    "    args.ann_file = \"data/coco2017/annotations/instances_val2017.json\"\n",
    "    args.ckpt_path = \"Varmedian/var-m-210.pth\"\n",
    "    args.results = os.path.join(os.path.dirname(args.ckpt_path), \"results.json\")\n",
    "    \n",
    "    args.batch_size = 32\n",
    "    args.iters = -1\n",
    "    \n",
    "    args.model_size = \"medium\"\n",
    "    args.kwargs = {\"img_sizes\": 420, \"score_thresh\": 0.1, \"detections\": 100} # mAP 34.6 FPS 451\n",
    "    #args.kwargs = {\"img_sizes\": 672, \"score_thresh\": 0.001, \"detections\": 300} # mAP 36.1. take more(2x-4x) time in total\n",
    "    args.evaluation = True\n",
    "    args.eval_with_loss = False\n",
    "    \n",
    "    main(args)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda: True\n",
      "available GPU(s): 1\n",
      "0: {'name': 'NVIDIA GeForce RTX 3060 Ti', 'capability': [8, 6], 'total_momory': 8.0, 'sm_count': 38}\n",
      "\n",
      "device: cuda\n",
      "Automatic mixed precision (AMP) is enabled!\n",
      "loading annotations into memory...\n",
      "Done (t=0.36s)\n",
      "creating index...\n",
      "index created!\n",
      "IoU metric: bbox\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.244\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.358\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.266\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.070\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.275\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.382\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.210\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.287\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.289\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.074\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.321\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.461\n",
      "\n",
      "evaluating...\n",
      "iter: 243.5, total: 117.8, model: 110.4\n",
      "all gather: 0.0s\n",
      "Loading and preparing results...\n",
      "DONE (t=0.04s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=9.28s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=1.43s).\n",
      "accumulate: 10.8s\n",
      "IoU metric: bbox\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.268\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.411\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.284\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.103\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.308\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.393\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.235\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.339\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.350\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.131\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.392\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.503\n",
      "\n",
      "\n",
      "total time of this evaluation: 50.93 s, speed: 289.73 FPS\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser()\n",
    "    args = parser.parse_args([]) # [] is needed when using Jupyter Notebook.\n",
    "    \n",
    "    args.use_cuda = True\n",
    "    \n",
    "    args.dataset = \"coco\"\n",
    "    args.file_root = \"data/coco2017/val2017\"\n",
    "    args.ann_file = \"data/coco2017/annotations/instances_val2017.json\"\n",
    "    args.ckpt_path = \"Varmedian/varmod-m-210.pth\"\n",
    "    args.results = os.path.join(os.path.dirname(args.ckpt_path), \"results.json\")\n",
    "    \n",
    "    args.batch_size = 32\n",
    "    args.iters = -1\n",
    "    \n",
    "    args.model_size = \"medium\"\n",
    "    args.kwargs = {\"img_sizes\": 420, \"score_thresh\": 0.1, \"detections\": 100} # mAP 34.6 FPS 451\n",
    "    #args.kwargs = {\"img_sizes\": 672, \"score_thresh\": 0.001, \"detections\": 300} # mAP 36.1. take more(2x-4x) time in total\n",
    "    args.evaluation = True\n",
    "    args.eval_with_loss = False\n",
    "    \n",
    "    main(args)\n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
