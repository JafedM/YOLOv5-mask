{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import time\n",
    "import torch\n",
    "import yolo\n",
    "\n",
    "    \n",
    "def main(args):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() and args.use_cuda else \"cpu\")\n",
    "    cuda = device.type == \"cuda\"\n",
    "    if cuda: yolo.get_gpu_prop(show=True)\n",
    "    print(\"\\ndevice: {}\".format(device))\n",
    "    \n",
    "    args.amp = False\n",
    "    if cuda and torch.__version__ >= \"1.6.0\":\n",
    "        capability = torch.cuda.get_device_capability()[0]\n",
    "        if capability >= 7: # 7 refers to RTX series GPUs\n",
    "            args.amp = True\n",
    "            print(\"Automatic mixed precision (AMP) is enabled!\")\n",
    "            \n",
    "    # ---------------------- prepare data loader ------------------------------- #\n",
    "    \n",
    "    DALI = cuda & yolo.DALI & (args.dataset == \"coco\")\n",
    "    \n",
    "    if DALI:\n",
    "        print(\"Nvidia DALI is utilized!\")\n",
    "        d_test = yolo.DALICOCODataLoader(\n",
    "            args.file_root, args.ann_file, args.batch_size, collate_fn=yolo.collate_wrapper)\n",
    "    else:\n",
    "        dataset_test = yolo.datasets(args.dataset, args.file_root, args.ann_file, train=True) # set train=True for eval\n",
    "        sampler_test = torch.utils.data.SequentialSampler(dataset_test)\n",
    "\n",
    "        batch_sampler_test = yolo.GroupedBatchSampler(\n",
    "            sampler_test, dataset_test.aspect_ratios, args.batch_size)\n",
    "        \n",
    "        args.num_workers = min(os.cpu_count() // 2, 8, args.batch_size if args.batch_size > 1 else 0)\n",
    "        data_loader_test = torch.utils.data.DataLoader(\n",
    "            dataset_test, batch_sampler=batch_sampler_test, num_workers=args.num_workers,  \n",
    "            collate_fn=yolo.collate_wrapper, pin_memory=cuda)\n",
    "\n",
    "        d_test = yolo.DataPrefetcher(data_loader_test) if cuda else data_loader_test\n",
    "    \n",
    "    # -------------------------------------------------------------------------- #\n",
    "\n",
    "    yolo.setup_seed(3)\n",
    "    \n",
    "    model_sizes = {\"small\": (0.33, 0.5), \"medium\": (0.67, 0.75), \"large\": (1, 1), \"extreme\": (1.33, 1.25)}\n",
    "    num_classes = len(d_test.dataset.classes)\n",
    "    model = yolo.YOLOv5(num_classes, model_sizes[args.model_size], **args.kwargs).to(device)\n",
    "    model.head.eval_with_loss = args.eval_with_loss\n",
    "    \n",
    "    checkpoint = torch.load(args.ckpt_path, map_location=device)\n",
    "    if \"ema\" in checkpoint:\n",
    "        model.load_state_dict(checkpoint[\"ema\"][0])\n",
    "        print(checkpoint[\"eval_info\"])\n",
    "    else:\n",
    "        model.load_state_dict(checkpoint)\n",
    "\n",
    "    model.fuse()\n",
    "    print(\"evaluating...\")\n",
    "    B = time.time()\n",
    "    eval_output, iter_eval = yolo.evaluate(model, d_test, device, args, evaluation=args.evaluation)\n",
    "    B = time.time() - B\n",
    "    print(eval_output)\n",
    "    print(\"\\ntotal time of this evaluation: {:.2f} s, speed: {:.2f} FPS\".format(B, args.batch_size / iter_eval))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resultados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo mask small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda: True\n",
      "available GPU(s): 1\n",
      "0: {'name': 'NVIDIA GeForce RTX 3060 Ti', 'capability': [8, 6], 'total_momory': 8.0, 'sm_count': 38}\n",
      "\n",
      "device: cuda\n",
      "Automatic mixed precision (AMP) is enabled!\n",
      "loading annotations into memory...\n",
      "Done (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "IoU metric: bbox\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.209\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.332\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.225\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.061\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.230\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.327\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.190\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.260\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.262\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.072\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.282\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.415\n",
      "\n",
      "evaluating...\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Sizes of tensors must match except in dimension 1. Expected size 2 but got size 1 for tensor number 4 in the list.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\jafse\\Documents\\Maestria cimat\\Proyecto tecnologico\\YOLOv5-mask\\eval copy 2.ipynb Cell 5\u001b[0m line \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/jafse/Documents/Maestria%20cimat/Proyecto%20tecnologico/YOLOv5-mask/eval%20copy%202.ipynb#W4sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m args\u001b[39m.\u001b[39mevaluation \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/jafse/Documents/Maestria%20cimat/Proyecto%20tecnologico/YOLOv5-mask/eval%20copy%202.ipynb#W4sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m args\u001b[39m.\u001b[39meval_with_loss \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/jafse/Documents/Maestria%20cimat/Proyecto%20tecnologico/YOLOv5-mask/eval%20copy%202.ipynb#W4sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m main(args)\n",
      "\u001b[1;32mc:\\Users\\jafse\\Documents\\Maestria cimat\\Proyecto tecnologico\\YOLOv5-mask\\eval copy 2.ipynb Cell 5\u001b[0m line \u001b[0;36m6\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/jafse/Documents/Maestria%20cimat/Proyecto%20tecnologico/YOLOv5-mask/eval%20copy%202.ipynb#W4sZmlsZQ%3D%3D?line=59'>60</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mevaluating...\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/jafse/Documents/Maestria%20cimat/Proyecto%20tecnologico/YOLOv5-mask/eval%20copy%202.ipynb#W4sZmlsZQ%3D%3D?line=60'>61</a>\u001b[0m B \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/jafse/Documents/Maestria%20cimat/Proyecto%20tecnologico/YOLOv5-mask/eval%20copy%202.ipynb#W4sZmlsZQ%3D%3D?line=61'>62</a>\u001b[0m eval_output, iter_eval \u001b[39m=\u001b[39m yolo\u001b[39m.\u001b[39;49mevaluate(model, d_test, device, args, evaluation\u001b[39m=\u001b[39;49margs\u001b[39m.\u001b[39;49mevaluation)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/jafse/Documents/Maestria%20cimat/Proyecto%20tecnologico/YOLOv5-mask/eval%20copy%202.ipynb#W4sZmlsZQ%3D%3D?line=62'>63</a>\u001b[0m B \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m B\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/jafse/Documents/Maestria%20cimat/Proyecto%20tecnologico/YOLOv5-mask/eval%20copy%202.ipynb#W4sZmlsZQ%3D%3D?line=63'>64</a>\u001b[0m \u001b[39mprint\u001b[39m(eval_output)\n",
      "File \u001b[1;32mc:\\Users\\jafse\\Documents\\Maestria cimat\\Proyecto tecnologico\\YOLOv5-mask\\yolo\\engine.py:91\u001b[0m, in \u001b[0;36mevaluate\u001b[1;34m(model, data_loader, device, args, generate, evaluation)\u001b[0m\n\u001b[0;32m     89\u001b[0m iter_eval \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     90\u001b[0m \u001b[39mif\u001b[39;00m generate:\n\u001b[1;32m---> 91\u001b[0m     iter_eval \u001b[39m=\u001b[39m generate_results(model, data_loader, device, args)\n\u001b[0;32m     93\u001b[0m output \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     94\u001b[0m \u001b[39mif\u001b[39;00m distributed\u001b[39m.\u001b[39mget_rank() \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m \u001b[39mand\u001b[39;00m evaluation:\n",
      "File \u001b[1;32mc:\\Users\\jafse\\ML\\lib\\site-packages\\torch\\utils\\_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[0;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecorate_context\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m    114\u001b[0m     \u001b[39mwith\u001b[39;00m ctx_factory():\n\u001b[1;32m--> 115\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\jafse\\Documents\\Maestria cimat\\Proyecto tecnologico\\YOLOv5-mask\\yolo\\engine.py:139\u001b[0m, in \u001b[0;36mgenerate_results\u001b[1;34m(model, data_loader, device, args)\u001b[0m\n\u001b[0;32m    137\u001b[0m \u001b[39mif\u001b[39;00m args\u001b[39m.\u001b[39mamp:\n\u001b[0;32m    138\u001b[0m     \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mcuda\u001b[39m.\u001b[39mamp\u001b[39m.\u001b[39mautocast():\n\u001b[1;32m--> 139\u001b[0m         outputs, losses \u001b[39m=\u001b[39m model(images, targets)\n\u001b[0;32m    140\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    141\u001b[0m     outputs, losses \u001b[39m=\u001b[39m model(images, targets)\n",
      "File \u001b[1;32mc:\\Users\\jafse\\ML\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\jafse\\Documents\\Maestria cimat\\Proyecto tecnologico\\YOLOv5-mask\\yolo\\model\\yolo.py:60\u001b[0m, in \u001b[0;36mYOLOv5.forward\u001b[1;34m(self, images, targets)\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     59\u001b[0m     max_size \u001b[39m=\u001b[39m \u001b[39mmax\u001b[39m(images\u001b[39m.\u001b[39mshape[\u001b[39m2\u001b[39m:])\n\u001b[1;32m---> 60\u001b[0m     results, losses \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mhead(features, targets, image_shapes, scale_factors, max_size)\n\u001b[0;32m     61\u001b[0m     \u001b[39mreturn\u001b[39;00m results, losses\n",
      "File \u001b[1;32mc:\\Users\\jafse\\ML\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\jafse\\Documents\\Maestria cimat\\Proyecto tecnologico\\YOLOv5-mask\\yolo\\model\\head.py:32\u001b[0m, in \u001b[0;36mHead.forward\u001b[1;34m(self, features, targets, image_shapes, scale_factors, max_size)\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, features, targets, image_shapes\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, scale_factors\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, max_size\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m---> 32\u001b[0m     preds \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpredictor(features)\n\u001b[0;32m     34\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining:\n\u001b[0;32m     35\u001b[0m         losses \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcompute_loss(preds, targets)\n",
      "File \u001b[1;32mc:\\Users\\jafse\\ML\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\jafse\\Documents\\Maestria cimat\\Proyecto tecnologico\\YOLOv5-mask\\yolo\\model\\yolo.py:98\u001b[0m, in \u001b[0;36mPredictor.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     96\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(x)):\n\u001b[0;32m     97\u001b[0m     h, w \u001b[39m=\u001b[39m x[i]\u001b[39m.\u001b[39mshape[\u001b[39m-\u001b[39m\u001b[39m2\u001b[39m:]\n\u001b[1;32m---> 98\u001b[0m     pred \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmasks[i](x[i])\n\u001b[0;32m     99\u001b[0m     pred \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmlp[i](pred)\n\u001b[0;32m    100\u001b[0m     pred \u001b[39m=\u001b[39m pred\u001b[39m.\u001b[39mpermute(\u001b[39m0\u001b[39m, \u001b[39m2\u001b[39m, \u001b[39m3\u001b[39m, \u001b[39m1\u001b[39m)\u001b[39m.\u001b[39mreshape(N, h, w, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, L)\n",
      "File \u001b[1;32mc:\\Users\\jafse\\ML\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\jafse\\ML\\lib\\site-packages\\masksembles\\torch.py:48\u001b[0m, in \u001b[0;36mMasksembles2D.forward\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m     46\u001b[0m batch \u001b[39m=\u001b[39m inputs\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]\n\u001b[0;32m     47\u001b[0m x \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39msplit(inputs\u001b[39m.\u001b[39munsqueeze(\u001b[39m1\u001b[39m), batch \u001b[39m/\u001b[39m\u001b[39m/\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn, dim\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[1;32m---> 48\u001b[0m x \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mcat(x, dim\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\u001b[39m.\u001b[39mpermute([\u001b[39m1\u001b[39m, \u001b[39m0\u001b[39m, \u001b[39m2\u001b[39m, \u001b[39m3\u001b[39m, \u001b[39m4\u001b[39m])\n\u001b[0;32m     49\u001b[0m x \u001b[39m=\u001b[39m x \u001b[39m*\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmasks\u001b[39m.\u001b[39munsqueeze(\u001b[39m1\u001b[39m)\u001b[39m.\u001b[39munsqueeze(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\u001b[39m.\u001b[39munsqueeze(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m     50\u001b[0m x \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcat(torch\u001b[39m.\u001b[39msplit(x, \u001b[39m1\u001b[39m, dim\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m), dim\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Sizes of tensors must match except in dimension 1. Expected size 2 but got size 1 for tensor number 4 in the list."
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser()\n",
    "    args = parser.parse_args([]) # [] is needed when using Jupyter Notebook.\n",
    "    \n",
    "    args.use_cuda = True\n",
    "    \n",
    "    args.dataset = \"coco\"\n",
    "    args.file_root = \"data/VOC/val2017\"\n",
    "    args.ann_file = \"data/VOC/annotations/instances_val2017.json\"\n",
    "    args.ckpt_path = \"Varmedian/mask-s-200.pth\"\n",
    "    args.results = os.path.join(os.path.dirname(args.ckpt_path), \"results.json\")\n",
    "    \n",
    "    args.batch_size = 32\n",
    "    args.iters = -1\n",
    "    \n",
    "    args.model_size = \"small\"\n",
    "    args.kwargs = {\"img_sizes\": 420, \"score_thresh\": 0.1, \"detections\": 100} # mAP 34.6 FPS 451\n",
    "    #args.kwargs = {\"img_sizes\": 672, \"score_thresh\": 0.001, \"detections\": 300} # mAP 36.1. take more(2x-4x) time in total\n",
    "    args.evaluation = True\n",
    "    args.eval_with_loss = False\n",
    "    \n",
    "    main(args)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo mask medium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda: True\n",
      "available GPU(s): 1\n",
      "0: {'name': 'NVIDIA GeForce RTX 3060 Ti', 'capability': [8, 6], 'total_momory': 8.0, 'sm_count': 38}\n",
      "\n",
      "device: cuda\n",
      "Automatic mixed precision (AMP) is enabled!\n",
      "loading annotations into memory...\n",
      "Done (t=0.35s)\n",
      "creating index...\n",
      "index created!\n",
      "IoU metric: bbox\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.270\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.398\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.292\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.086\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.305\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.412\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.232\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.323\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.326\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.097\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.364\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.505\n",
      "\n",
      "evaluating...\n",
      "iter: 285.6, total: 159.7, model: 151.8\n",
      "all gather: 0.0s\n",
      "Loading and preparing results...\n",
      "DONE (t=0.04s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=10.03s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=1.60s).\n",
      "accumulate: 11.7s\n",
      "IoU metric: bbox\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.290\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.443\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.309\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.117\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.327\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.422\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.251\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.370\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.382\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.153\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.424\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.547\n",
      "\n",
      "\n",
      "total time of this evaluation: 58.44 s, speed: 210.78 FPS\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser()\n",
    "    args = parser.parse_args([]) # [] is needed when using Jupyter Notebook.\n",
    "    \n",
    "    args.use_cuda = True\n",
    "    \n",
    "    args.dataset = \"coco\"\n",
    "    args.file_root = \"data/coco2017/val2017\"\n",
    "    args.ann_file = \"data/coco2017/annotations/instances_val2017.json\"\n",
    "    args.ckpt_path = \"Varmedian/mask-m-200.pth\"\n",
    "    args.results = os.path.join(os.path.dirname(args.ckpt_path), \"results.json\")\n",
    "    \n",
    "    args.batch_size = 32\n",
    "    args.iters = -1\n",
    "    \n",
    "    args.model_size = \"medium\"\n",
    "    args.kwargs = {\"img_sizes\": 420, \"score_thresh\": 0.1, \"detections\": 100} # mAP 34.6 FPS 451\n",
    "    #args.kwargs = {\"img_sizes\": 672, \"score_thresh\": 0.001, \"detections\": 300} # mAP 36.1. take more(2x-4x) time in total\n",
    "    args.evaluation = True\n",
    "    args.eval_with_loss = False\n",
    "    \n",
    "    main(args)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VAR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo 10 fine small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda: True\n",
      "available GPU(s): 1\n",
      "0: {'name': 'NVIDIA GeForce RTX 3060 Ti', 'capability': [8, 6], 'total_momory': 8.0, 'sm_count': 38}\n",
      "\n",
      "device: cuda\n",
      "Automatic mixed precision (AMP) is enabled!\n",
      "loading annotations into memory...\n",
      "Done (t=0.37s)\n",
      "creating index...\n",
      "index created!\n",
      "IoU metric: bbox\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.196\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.314\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.211\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.051\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.218\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.316\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.181\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.244\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.246\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.056\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.267\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.401\n",
      "\n",
      "evaluating...\n",
      "iter: 211.7, total: 86.4, model: 78.5\n",
      "all gather: 0.0s\n",
      "Loading and preparing results...\n",
      "DONE (t=0.23s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=10.20s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=1.57s).\n",
      "accumulate: 12.0s\n",
      "IoU metric: bbox\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.213\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.350\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.223\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.075\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.239\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.325\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.199\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.286\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.296\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.102\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.328\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.444\n",
      "\n",
      "\n",
      "total time of this evaluation: 47.32 s, speed: 407.40 FPS\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser()\n",
    "    args = parser.parse_args([]) # [] is needed when using Jupyter Notebook.\n",
    "    \n",
    "    args.use_cuda = True\n",
    "    \n",
    "    args.dataset = \"coco\"\n",
    "    args.file_root = \"data/coco2017/val2017\"\n",
    "    args.ann_file = \"data/coco2017/annotations/instances_val2017.json\"\n",
    "    args.ckpt_path = \"Varmedian/var-s-210.pth\"\n",
    "    args.results = os.path.join(os.path.dirname(args.ckpt_path), \"results.json\")\n",
    "    \n",
    "    args.batch_size = 32\n",
    "    args.iters = -1\n",
    "    \n",
    "    args.model_size = \"small\"\n",
    "    args.kwargs = {\"img_sizes\": 420, \"score_thresh\": 0.1, \"detections\": 100} # mAP 34.6 FPS 451\n",
    "    #args.kwargs = {\"img_sizes\": 672, \"score_thresh\": 0.001, \"detections\": 300} # mAP 36.1. take more(2x-4x) time in total\n",
    "    args.evaluation = True\n",
    "    args.eval_with_loss = False\n",
    "    \n",
    "    main(args)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda: True\n",
      "available GPU(s): 1\n",
      "0: {'name': 'NVIDIA GeForce RTX 3060 Ti', 'capability': [8, 6], 'total_momory': 8.0, 'sm_count': 38}\n",
      "\n",
      "device: cuda\n",
      "Automatic mixed precision (AMP) is enabled!\n",
      "loading annotations into memory...\n",
      "Done (t=0.56s)\n",
      "creating index...\n",
      "index created!\n",
      "IoU metric: bbox\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.199\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.314\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.215\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.053\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.223\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.313\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.181\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.245\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.247\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.058\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.270\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.396\n",
      "\n",
      "evaluating...\n",
      "iter: 214.3, total: 89.8, model: 80.6\n",
      "all gather: 0.0s\n",
      "Loading and preparing results...\n",
      "DONE (t=0.04s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=9.90s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=1.51s).\n",
      "accumulate: 11.5s\n",
      "IoU metric: bbox\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.213\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.348\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.226\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.078\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.243\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.323\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.199\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.287\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.296\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.105\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.329\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.440\n",
      "\n",
      "\n",
      "total time of this evaluation: 47.18 s, speed: 396.91 FPS\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser()\n",
    "    args = parser.parse_args([]) # [] is needed when using Jupyter Notebook.\n",
    "    \n",
    "    args.use_cuda = True\n",
    "    \n",
    "    args.dataset = \"coco\"\n",
    "    args.file_root = \"data/coco2017/val2017\"\n",
    "    args.ann_file = \"data/coco2017/annotations/instances_val2017.json\"\n",
    "    args.ckpt_path = \"Varmedian/varmod-s-210.pth\"\n",
    "    args.results = os.path.join(os.path.dirname(args.ckpt_path), \"results.json\")\n",
    "    \n",
    "    args.batch_size = 32\n",
    "    args.iters = -1\n",
    "    \n",
    "    args.model_size = \"small\"\n",
    "    args.kwargs = {\"img_sizes\": 420, \"score_thresh\": 0.1, \"detections\": 100} # mAP 34.6 FPS 451\n",
    "    #args.kwargs = {\"img_sizes\": 672, \"score_thresh\": 0.001, \"detections\": 300} # mAP 36.1. take more(2x-4x) time in total\n",
    "    args.evaluation = True\n",
    "    args.eval_with_loss = False\n",
    "    \n",
    "    main(args)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo 10 fine medium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda: True\n",
      "available GPU(s): 1\n",
      "0: {'name': 'NVIDIA GeForce RTX 3060 Ti', 'capability': [8, 6], 'total_momory': 8.0, 'sm_count': 38}\n",
      "\n",
      "device: cuda\n",
      "Automatic mixed precision (AMP) is enabled!\n",
      "loading annotations into memory...\n",
      "Done (t=0.36s)\n",
      "creating index...\n",
      "index created!\n",
      "IoU metric: bbox\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.240\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.359\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.261\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.068\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.269\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.378\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.208\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.282\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.285\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.073\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.317\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.457\n",
      "\n",
      "evaluating...\n",
      "iter: 242.9, total: 115.5, model: 108.2\n",
      "all gather: 0.0s\n",
      "Loading and preparing results...\n",
      "DONE (t=0.04s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=10.19s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=1.47s).\n",
      "accumulate: 11.7s\n",
      "IoU metric: bbox\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.262\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.409\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.276\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.098\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.300\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.383\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.232\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.335\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.346\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.130\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.387\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.496\n",
      "\n",
      "\n",
      "total time of this evaluation: 51.90 s, speed: 295.64 FPS\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser()\n",
    "    args = parser.parse_args([]) # [] is needed when using Jupyter Notebook.\n",
    "    \n",
    "    args.use_cuda = True\n",
    "    \n",
    "    args.dataset = \"coco\"\n",
    "    args.file_root = \"data/coco2017/val2017\"\n",
    "    args.ann_file = \"data/coco2017/annotations/instances_val2017.json\"\n",
    "    args.ckpt_path = \"Varmedian/var-m-210.pth\"\n",
    "    args.results = os.path.join(os.path.dirname(args.ckpt_path), \"results.json\")\n",
    "    \n",
    "    args.batch_size = 32\n",
    "    args.iters = -1\n",
    "    \n",
    "    args.model_size = \"medium\"\n",
    "    args.kwargs = {\"img_sizes\": 420, \"score_thresh\": 0.1, \"detections\": 100} # mAP 34.6 FPS 451\n",
    "    #args.kwargs = {\"img_sizes\": 672, \"score_thresh\": 0.001, \"detections\": 300} # mAP 36.1. take more(2x-4x) time in total\n",
    "    args.evaluation = True\n",
    "    args.eval_with_loss = False\n",
    "    \n",
    "    main(args)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda: True\n",
      "available GPU(s): 1\n",
      "0: {'name': 'NVIDIA GeForce RTX 3060 Ti', 'capability': [8, 6], 'total_momory': 8.0, 'sm_count': 38}\n",
      "\n",
      "device: cuda\n",
      "Automatic mixed precision (AMP) is enabled!\n",
      "loading annotations into memory...\n",
      "Done (t=0.36s)\n",
      "creating index...\n",
      "index created!\n",
      "IoU metric: bbox\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.244\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.358\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.266\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.070\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.275\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.382\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.210\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.287\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.289\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.074\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.321\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.461\n",
      "\n",
      "evaluating...\n",
      "iter: 243.5, total: 117.8, model: 110.4\n",
      "all gather: 0.0s\n",
      "Loading and preparing results...\n",
      "DONE (t=0.04s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=9.28s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=1.43s).\n",
      "accumulate: 10.8s\n",
      "IoU metric: bbox\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.268\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.411\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.284\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.103\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.308\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.393\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.235\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.339\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.350\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.131\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.392\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.503\n",
      "\n",
      "\n",
      "total time of this evaluation: 50.93 s, speed: 289.73 FPS\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser()\n",
    "    args = parser.parse_args([]) # [] is needed when using Jupyter Notebook.\n",
    "    \n",
    "    args.use_cuda = True\n",
    "    \n",
    "    args.dataset = \"coco\"\n",
    "    args.file_root = \"data/coco2017/val2017\"\n",
    "    args.ann_file = \"data/coco2017/annotations/instances_val2017.json\"\n",
    "    args.ckpt_path = \"Varmedian/varmod-m-210.pth\"\n",
    "    args.results = os.path.join(os.path.dirname(args.ckpt_path), \"results.json\")\n",
    "    \n",
    "    args.batch_size = 32\n",
    "    args.iters = -1\n",
    "    \n",
    "    args.model_size = \"medium\"\n",
    "    args.kwargs = {\"img_sizes\": 420, \"score_thresh\": 0.1, \"detections\": 100} # mAP 34.6 FPS 451\n",
    "    #args.kwargs = {\"img_sizes\": 672, \"score_thresh\": 0.001, \"detections\": 300} # mAP 36.1. take more(2x-4x) time in total\n",
    "    args.evaluation = True\n",
    "    args.eval_with_loss = False\n",
    "    \n",
    "    main(args)\n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
